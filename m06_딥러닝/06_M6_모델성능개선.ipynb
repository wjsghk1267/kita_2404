{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxlvcpoflviO0514ReeCui"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_ItHIVEhVOk","executionInfo":{"status":"ok","timestamp":1723079259968,"user_tz":-540,"elapsed":54951,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"c76e2863-c534-4d09-f72a-86cf625ffabc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## 와인의 종류 예측하기\n","\n","- 속성 12개 : 주석산 농도, 아세트산 농도, 구연산 농도, 잔류 당분 농도, 염화나트륨 농도, 유리 아황산 농도, 총 아황산 농도, 밀도, pH, 황산칼륨 농도, 알코올 도수, 와인의 맛(0~10등급), 클래스(1:레드 와인, 0: 화이트 와인)"],"metadata":{"id":"lQONPlfWhv-_"}},{"cell_type":"markdown","source":["Q. wine.csv로 와의 품종을 예측하는 모델을 텐서플로/케라스로 아래와 같이 생성하고 학습 및 평가를 수행하세요.\n","- 입력층 :  Input 레이어 shape=(12,)\n","- 첫번째층 : 30, activation='relu'\n","- 두번째층 :12, activation='relu'\n","- 세번째층 :8, activation='relu'\n","- 출력층 :1, activation='sigmoid'"],"metadata":{"id":"RzDonaIBhYy2"}},{"cell_type":"markdown","source":["### seed 설정\n","- NumPy의 무작위 작업에 대한 전역 제어를 위해 np.random.seed를 설정.\n","- np.random.seed(123)를 설정해도 스크립트를 실행할 때마다 정확히 동일한 학습 평가데이터 분할이 재현되도록 보장하려는 경우 train_test_split과 같은 scikit-learn 함수에 random_state를 지정.\n","- TensorFlow를 사용하는 경우 TensorFlow 작업에 tf.random.set_seed를 사용하며 신경망 레이어의 무작위 가중치 초기화, 훈련 프로세스의 임의성(예: , 이 특정 코드에 없는 드롭아웃 레이어를 사용하는 경우) 또는 임의성을 포함하는 기타 TensorFlow 작업을 사용하는 경우에 적용. 단순한 모델이나 특정 데이터 세트에 대해 훈련된 모델은 다양한 초기화에서 성능에 큰 변화를 나타내지 않을 수 있다\n","- Python 내장 random 모듈이 스크립트의 어느 곳에서나 사용되는 경우 해당 모듈의 시드를 설정. TensorFlow 작업 자체에 'python_random.seed(123)'를 직접 사용할 필요가 없지만 스크립트 시작 부분에 python_random.seed(123)를 설정하면 난수 생성을 위해 내장된 python random 모듈을 사용하는 모든 Python 작업에 영향을 미칠 수 있다."],"metadata":{"id":"ogJ5OFpChu3c"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/kdt_240424/m6_딥러닝/data/wine.csv\")"],"metadata":{"id":"oClt4YzDhfWZ","executionInfo":{"status":"ok","timestamp":1723079293650,"user_tz":-540,"elapsed":1317,"user":{"displayName":"김홍준","userId":"01118584956690988204"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkjD7Lv1h6fJ","executionInfo":{"status":"ok","timestamp":1723079331495,"user_tz":-540,"elapsed":360,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"e24eb1b1-a278-4130-f5df-b07f458debed"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6496 entries, 0 to 6495\n","Data columns (total 13 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   7.4     6496 non-null   float64\n"," 1   0.7     6496 non-null   float64\n"," 2   0       6496 non-null   float64\n"," 3   1.9     6496 non-null   float64\n"," 4   0.076   6496 non-null   float64\n"," 5   11      6496 non-null   float64\n"," 6   34      6496 non-null   float64\n"," 7   0.9978  6496 non-null   float64\n"," 8   3.51    6496 non-null   float64\n"," 9   0.56    6496 non-null   float64\n"," 10  9.4     6496 non-null   float64\n"," 11  5       6496 non-null   int64  \n"," 12  1       6496 non-null   int64  \n","dtypes: float64(11), int64(2)\n","memory usage: 659.9 KB\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","X = df.iloc[:,0:12]\n","y = df.iloc[:,12]\n","\n","# 학습셋, 테스트셋\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n","\n","# 모델구조\n","model = Sequential()\n","model.add(Dense(30, input_dim=12, activation='relu'))\n","model.add(Dense(12, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 모델 컴파일\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 모델 학습\n","model.fit(X_train, y_train, epochs=200, batch_size=200)\n","\n","# 모델 평가\n","model.evaluate(X_test, y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFi2Gp0Gmm62","executionInfo":{"status":"ok","timestamp":1723081225313,"user_tz":-540,"elapsed":34463,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"573eeedb-eca1-409c-f476-b56f7fc96e61"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3640\n","Epoch 2/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9345 - loss: 0.2055\n","Epoch 3/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1733\n","Epoch 4/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.1860 \n","Epoch 5/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1689 \n","Epoch 6/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1740 \n","Epoch 7/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1672 \n","Epoch 8/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1550 \n","Epoch 9/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1543 \n","Epoch 10/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9543 - loss: 0.1426 \n","Epoch 11/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1461 \n","Epoch 12/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1419 \n","Epoch 13/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1423\n","Epoch 14/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1417\n","Epoch 15/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1281 \n","Epoch 16/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1295 \n","Epoch 17/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1209 \n","Epoch 18/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1218\n","Epoch 19/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1197 \n","Epoch 20/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1173\n","Epoch 21/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1151\n","Epoch 22/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1136\n","Epoch 23/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1069\n","Epoch 24/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.1043\n","Epoch 25/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1051\n","Epoch 26/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1040 \n","Epoch 27/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.0925 \n","Epoch 28/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.1023\n","Epoch 29/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.0927\n","Epoch 30/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0917\n","Epoch 31/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0974 \n","Epoch 32/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0859\n","Epoch 33/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0853\n","Epoch 34/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1028 \n","Epoch 35/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1055 \n","Epoch 36/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0698\n","Epoch 37/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0800\n","Epoch 38/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0851\n","Epoch 39/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0836\n","Epoch 40/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0684\n","Epoch 41/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0726\n","Epoch 42/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0781\n","Epoch 43/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0806\n","Epoch 44/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0825\n","Epoch 45/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0761\n","Epoch 46/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0706\n","Epoch 47/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0780\n","Epoch 48/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0783\n","Epoch 49/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0719\n","Epoch 50/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0704\n","Epoch 51/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0729\n","Epoch 52/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0720\n","Epoch 53/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0718  \n","Epoch 54/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0723\n","Epoch 55/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0590 \n","Epoch 56/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0660 \n","Epoch 57/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0664\n","Epoch 58/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0676 \n","Epoch 59/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0650 \n","Epoch 60/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.0790\n","Epoch 61/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0606 \n","Epoch 62/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0642\n","Epoch 63/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0671 \n","Epoch 64/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0563 \n","Epoch 65/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0640 \n","Epoch 66/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0598 \n","Epoch 67/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0622 \n","Epoch 68/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0660\n","Epoch 69/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0584 \n","Epoch 70/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0672 \n","Epoch 71/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0583 \n","Epoch 72/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0578 \n","Epoch 73/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0630\n","Epoch 74/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0581 \n","Epoch 75/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0564 \n","Epoch 76/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0524 \n","Epoch 77/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0651 \n","Epoch 78/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0543 \n","Epoch 79/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0598 \n","Epoch 80/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0461\n","Epoch 81/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0573 \n","Epoch 82/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0585 \n","Epoch 83/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0591 \n","Epoch 84/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0578\n","Epoch 85/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0596 \n","Epoch 86/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0633 \n","Epoch 87/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0494 \n","Epoch 88/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0515\n","Epoch 89/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0599 \n","Epoch 90/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0591 \n","Epoch 91/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0535 \n","Epoch 92/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0577 \n","Epoch 93/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0418 \n","Epoch 94/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0527 \n","Epoch 95/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0603 \n","Epoch 96/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0671\n","Epoch 97/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0544\n","Epoch 98/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0533 \n","Epoch 99/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0496 \n","Epoch 100/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0507 \n","Epoch 101/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0547 \n","Epoch 102/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0596 \n","Epoch 103/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0486 \n","Epoch 104/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0531\n","Epoch 105/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0626\n","Epoch 106/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0492 \n","Epoch 107/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0532 \n","Epoch 108/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0544 \n","Epoch 109/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0567 \n","Epoch 110/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0346 \n","Epoch 111/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0680 \n","Epoch 112/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0517\n","Epoch 113/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0499\n","Epoch 114/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0608 \n","Epoch 115/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0409\n","Epoch 116/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0429 \n","Epoch 117/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0491 \n","Epoch 118/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0451 \n","Epoch 119/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0445 \n","Epoch 120/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0451\n","Epoch 121/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0520\n","Epoch 122/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0485 \n","Epoch 123/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0472\n","Epoch 124/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0535 \n","Epoch 125/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0456 \n","Epoch 126/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0452\n","Epoch 127/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0555\n","Epoch 128/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0538\n","Epoch 129/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0483\n","Epoch 130/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0493 \n","Epoch 131/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0469\n","Epoch 132/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0453\n","Epoch 133/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0463\n","Epoch 134/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0455\n","Epoch 135/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0552\n","Epoch 136/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0402\n","Epoch 137/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0471\n","Epoch 138/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0496\n","Epoch 139/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0547\n","Epoch 140/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0448\n","Epoch 141/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0454\n","Epoch 142/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0323\n","Epoch 143/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0421\n","Epoch 144/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0432\n","Epoch 145/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0560\n","Epoch 146/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0364\n","Epoch 147/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0396\n","Epoch 148/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0549\n","Epoch 149/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0367\n","Epoch 150/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0431\n","Epoch 151/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0404\n","Epoch 152/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0530\n","Epoch 153/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0380\n","Epoch 154/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0572\n","Epoch 155/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0443  \n","Epoch 156/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0437\n","Epoch 157/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0437 \n","Epoch 158/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0408 \n","Epoch 159/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0497\n","Epoch 160/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0483\n","Epoch 161/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0436\n","Epoch 162/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0475 \n","Epoch 163/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0413\n","Epoch 164/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0546\n","Epoch 165/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0429\n","Epoch 166/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0470\n","Epoch 167/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0605 \n","Epoch 168/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0448\n","Epoch 169/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0410\n","Epoch 170/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0481\n","Epoch 171/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0395\n","Epoch 172/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0400\n","Epoch 173/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0421\n","Epoch 174/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0338\n","Epoch 175/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0424\n","Epoch 176/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0463\n","Epoch 177/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0370\n","Epoch 178/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0391\n","Epoch 179/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0440\n","Epoch 180/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0510\n","Epoch 181/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0505\n","Epoch 182/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0464\n","Epoch 183/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0489\n","Epoch 184/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0402\n","Epoch 185/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0439\n","Epoch 186/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0416 \n","Epoch 187/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0427\n","Epoch 188/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0398\n","Epoch 189/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0336\n","Epoch 190/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0388\n","Epoch 191/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0383\n","Epoch 192/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0454\n","Epoch 193/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0367\n","Epoch 194/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0481\n","Epoch 195/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0393\n","Epoch 196/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0348\n","Epoch 197/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0351\n","Epoch 198/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0431\n","Epoch 199/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0484\n","Epoch 200/200\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0469\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0511\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.04547794163227081, 0.9884615540504456]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":[".keras 파일\n","- 기본적으로 TensorFlow의 SavedModel 형식을 따릅니다. 이는 TensorFlow의 공식 모델 저장 형식으로, 모델 아키텍처, 가중치, 그리고 훈련 구성(옵티마이저 상태 등)을 포함할 수 있습니다."],"metadata":{"id":"RNNZrRHNpQFS"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","#모델 저장 조건 설정\n","modelpath=\"/content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n","checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n","\n","# 모델 실행\n","history = model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8sGqiLopShT","executionInfo":{"status":"ok","timestamp":1723081454413,"user_tz":-540,"elapsed":10043,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"19663c2d-8c64-4ee8-b4b8-5f1426cfcd2c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/01-0.9908.keras\n","\n","Epoch 2: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/02-0.9915.keras\n","\n","Epoch 3: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/03-0.9846.keras\n","\n","Epoch 4: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/04-0.9923.keras\n","\n","Epoch 5: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/05-0.9915.keras\n","\n","Epoch 6: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/06-0.9908.keras\n","\n","Epoch 7: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/07-0.9908.keras\n","\n","Epoch 8: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/08-0.9915.keras\n","\n","Epoch 9: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/09-0.9892.keras\n","\n","Epoch 10: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/10-0.9885.keras\n","\n","Epoch 11: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/11-0.9915.keras\n","\n","Epoch 12: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/12-0.9915.keras\n","\n","Epoch 13: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/13-0.9900.keras\n","\n","Epoch 14: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/14-0.9885.keras\n","\n","Epoch 15: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/15-0.9900.keras\n","\n","Epoch 16: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/16-0.9908.keras\n","\n","Epoch 17: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/17-0.9892.keras\n","\n","Epoch 18: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/18-0.9915.keras\n","\n","Epoch 19: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/19-0.9900.keras\n","\n","Epoch 20: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/20-0.9908.keras\n","\n","Epoch 21: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/21-0.9908.keras\n","\n","Epoch 22: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/22-0.9885.keras\n","\n","Epoch 23: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/23-0.9892.keras\n","\n","Epoch 24: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/24-0.9885.keras\n","\n","Epoch 25: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/25-0.9892.keras\n","\n","Epoch 26: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/26-0.9915.keras\n","\n","Epoch 27: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/27-0.9877.keras\n","\n","Epoch 28: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/28-0.9900.keras\n","\n","Epoch 29: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/29-0.9915.keras\n","\n","Epoch 30: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/30-0.9923.keras\n","\n","Epoch 31: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/31-0.9923.keras\n","\n","Epoch 32: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/32-0.9838.keras\n","\n","Epoch 33: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/33-0.9915.keras\n","\n","Epoch 34: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/34-0.9923.keras\n","\n","Epoch 35: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/35-0.9900.keras\n","\n","Epoch 36: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/36-0.9900.keras\n","\n","Epoch 37: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/37-0.9923.keras\n","\n","Epoch 38: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/38-0.9908.keras\n","\n","Epoch 39: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/39-0.9892.keras\n","\n","Epoch 40: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/40-0.9892.keras\n","\n","Epoch 41: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/41-0.9915.keras\n","\n","Epoch 42: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/42-0.9915.keras\n","\n","Epoch 43: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/43-0.9854.keras\n","\n","Epoch 44: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/44-0.9915.keras\n","\n","Epoch 45: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/45-0.9892.keras\n","\n","Epoch 46: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/46-0.9892.keras\n","\n","Epoch 47: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/47-0.9915.keras\n","\n","Epoch 48: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/48-0.9915.keras\n","\n","Epoch 49: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/49-0.9923.keras\n","\n","Epoch 50: saving model to /content/drive/MyDrive/kdt_240424/m6_딥러닝/data/model/all/50-0.9892.keras\n"]}]},{"cell_type":"code","source":["# 테스트 결과를 출력\n","score=model.evaluate(X_test, y_test)\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BE4-y6DqM8u","executionInfo":{"status":"ok","timestamp":1723081502411,"user_tz":-540,"elapsed":351,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"5db28da6-21d4-412f-a9b8-bf8a85ccb898"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0507 \n","Test accuracy: 0.9884615540504456\n"]}]},{"cell_type":"markdown","source":["History 객체\n","\n","- 신경망 훈련을 위해 Keras 또는 TensorFlow 사용 시 model.fit()과 같은 호출로 훈련 작업을 실행하면 History 객체가 반환. 이 객체에는 연속적인 에포크의 훈련 손실 값과 측정항목 값 기록뿐만 아니라 해당하는 경우 검증 손실 값과 검증 측정항목 값도 포함.\n","- 코드에서 얻은 History 객체의 내용을 보려면 훈련 과정 중에 기록된 측정항목이 포함된 사전인 history 속성에 액세스. 'history.history' 사전의 각 키는 훈련 중에 모니터링된 측정항목에 해당"],"metadata":{"id":"RMTba8uoqn3j"}},{"cell_type":"code","source":["history.history.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"iRfHgpmHrkEb","executionInfo":{"status":"error","timestamp":1723083086457,"user_tz":-540,"elapsed":525,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"b8beff41-e071-425e-92cc-75a2eb14b3c8"},"execution_count":13,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'dict' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b2ffb63ec94e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# y_vloss에 테스트셋(여기선 검증셋)의 오차를 저장.\n","y_vloss=history.history['val_loss']\n","\n","# y_loss에 학습셋의 오차 저장\n","y_loss=history.history['loss']\n","\n","# 파란색 점선으로 훈련셋의 오차를 표시.\n","x_len = np.arange(len(y_vloss))\n","plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Validation loss')\n","plt.plot(x_len, y_loss, \"o\", c=\"blue\", makersize=2, label=\"Training loss\")\n","\n","# 그래프에 그리드를 주고 레이블을 표시.\n","plt.grid()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(loc='upper right')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":786},"id":"Ws0aryk1wLMK","executionInfo":{"status":"error","timestamp":1723083207506,"user_tz":-540,"elapsed":957,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"3a1af023-d29a-410c-b736-ed3e21a15ae4"},"execution_count":15,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"Line2D.set() got an unexpected keyword argument 'makersize'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-80809e6a0159>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_vloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmakersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 그래프에 그리드를 주고 레이블을 표시.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         result = (make_artist(x[:, j % ncx], y[:, j % ncy], kw,\n\u001b[0m\u001b[1;32m    538\u001b[0m                               {**kwargs, 'label': label})\n\u001b[1;32m    539\u001b[0m                   for j, label in enumerate(labels))\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[0;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \"{prop_name!r}\")\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"set_{k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                         raise AttributeError(\n\u001b[0m\u001b[1;32m   1198\u001b[0m                             errfmt.format(cls=type(self), prop_name=k))\n\u001b[1;32m   1199\u001b[0m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Line2D.set() got an unexpected keyword argument 'makersize'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import os\n","import pandas as pd\n","import random as python_random\n","\n","np.random.seed(123)  # Numpy module.\n","python_random.seed(123)  # Python random module.\n","tf.random.set_seed(123)  # TensorFlow module.\n","\n","# 데이터를 입력합니다.\n","df = pd.read_csv(\"/content/drive/MyDrive/kdt_240424/m6_딥러닝/data/wine.csv\")\n","\n","# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n","X = df.iloc[:,0:12]\n","y = df.iloc[:,12]\n","\n","#학습셋과 테스트셋으로 나눕니다.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n","\n","# 모델 구조를 설정합니다.\n","model = Sequential()\n","model.add(Dense(30,  input_dim=12, activation='relu'))\n","model.add(Dense(12, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","#모델을 컴파일합니다.\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"qDK8nz9gzigB","executionInfo":{"status":"ok","timestamp":1723083944940,"user_tz":-540,"elapsed":915,"user":{"displayName":"김홍준","userId":"01118584956690988204"}},"outputId":"a046e62f-7dd2-4caf-ab33-1e1de6819d98"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["[ callback ]\n","\n","callbacks=[early_stopping_callback, checkpointer]\n","\n","학습 과정 중에 특정 이벤트가 발생했을 때, 취할 행동을 정의.\n","\n","- early_stopping_callback: 이 콜백은 모델의 성능이 더 이상 개선되지 않을 때 학습을 조기에 중단하도록 설정. 예를 들어, 검증 데이터에 대한 손실이 일정 기간 동안 개선되지 않으면 학습을 멈춘다. 이는 과적합을 방지하고 학습 시간을 단축시키는 데 도움이 된다.\n","- checkpointer: 이 콜백은 모델의 중간 학습 상태를 파일로 저장하여, 학습 과정에서 가장 좋은 모델을 보존할 수 있게 한다. 이를 통해 나중에 모델을 재사용하거나, 학습 과정이 끝난 후 최적의 모델 상태로 복원할 수 있다.\n","\n","이 코드는 신경망 모델의 학습 과정을 세밀하게 제어하면서, 과적합을 방지하고, 학습 과정에서 모델의 최적 상태를 저장하는 방법을 보여준다."],"metadata":{"id":"598gzqFE1juD"}}]}