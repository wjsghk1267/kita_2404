{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q-4-b9jr45v"
   },
   "source": [
    "Gradio는 Python 기반의 라이브러리로, 머신러닝 모델 또는 일반적인 함수와 사용자 간의 상호작용을 위한 웹 인터페이스를 간단하게 구축할 수 있도록 도와줍니다. Gradio를 사용하면 몇 줄의 코드로 웹 애플리케이션을 만들 수 있으며, 이를 통해 모델이나 함수를 사용자에게 쉽게 배포할 수 있습니다.\n",
    "\n",
    "**Gradio의 기본 개념**\n",
    "\n",
    "- 웹 인터페이스: Gradio는 머신러닝 모델 또는 일반적인 파이썬 함수를 웹 브라우저에서 실행할 수 있도록 UI를 제공합니다. 이를 통해 사용자는 모델을 직접 입력값을 주거나 결과를 확인할 수 있습니다.\n",
    "- 사용자 상호작용: Gradio는 텍스트 입력, 파일 업로드, 드롭다운 메뉴 등 다양한 위젯을 제공하여 사용자가 쉽게 상호작용할 수 있는 환경을 제공합니다.\n",
    "- 빠른 프로토타이핑: 복잡한 웹 서버 설정 없이도 간단하게 모델을 웹에서 테스트하고 배포할 수 있습니다.\n",
    "\n",
    "**Gradio의 핵심 기능**\n",
    "- 인터페이스 구성 요소:\n",
    "Gradio는 다양한 입력 및 출력 위젯을 제공합니다. 이를 사용하여 웹 기반 인터페이스를 만들 수 있습니다.\n",
    "  - 입력 위젯: Textbox, Dropdown, Slider, Checkbox, FileUpload 등\n",
    "  - 출력 위젯: Textbox, Label, Image, Audio, Video 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr1mpcWIwwa-"
   },
   "source": [
    "- Interface: Gradio의 기본 클래스입니다. 함수를 UI 위젯과 연결하여 웹 애플리케이션을 쉽게 만들 수 있습니다.\n",
    "  - fn: 실행할 함수\n",
    "  - inputs: 사용자 입력을 받는 위젯\n",
    "  - outputs: 함수의 결과를 표시하는 위젯\n",
    "  \n",
    "- Blocks: 복잡한 레이아웃을 만들거나 여러 위젯을 연결할 때 사용되는 블록 구조입니다. Blocks는 여러 컴포넌트를 모듈식으로 구성할 수 있으며, 복잡한 인터페이스를 구성할 때 유용합니다.\n",
    "\n",
    "- 상태 관리 (gr.State): 여러 함수 호출 간에 데이터를 저장하고 공유할 수 있는 기능입니다. 대화형 애플리케이션에서 상태를 유지하거나 이전 입력값을 저장할 때 사용됩니다.\n",
    "\n",
    "- 실시간 인터페이스: Gradio는 실시간으로 사용자 입력을 처리하고, 빠르게 결과를 반환할 수 있는 기능을 제공합니다. 이를 통해 데이터 분석, 이미지 생성, 챗봇 등 다양한 실시간 애플리케이션을 구축할 수 있습니다.\n",
    "\n",
    "- 파일 업로드 및 다운로드: Gradio는 파일을 업로드하거나 다운로드하는 기능을 제공하여 사용자와의 상호작용을 더욱 다양화할 수 있습니다.\n",
    "\n",
    "- Markdown 지원: Gradio는 gr.Markdown()을 통해 인터페이스에서 간단한 텍스트 설명을 Markdown 형식으로 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19788,
     "status": "ok",
     "timestamp": 1724375055542,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "sv4boaj2rJjG",
    "outputId": "8f7736c5-1bcb-487b-b102-b0c26cdba717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.42.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m773.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.4)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-4.42.0-py3-none-any.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.13.2\n",
      "    Uninstalling tomlkit-0.13.2:\n",
      "      Successfully uninstalled tomlkit-0.13.2\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.112.1 ffmpy-0.4.0 gradio-4.42.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.2 semantic-version-2.10.0 starlette-0.38.2 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "executionInfo": {
     "elapsed": 5945,
     "status": "ok",
     "timestamp": 1724375183198,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "DVYtcZ8jxInR",
    "outputId": "4006b8d7-4d94-4c51-c94b-23ef21409faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://3576abe1f32dc686f6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3576abe1f32dc686f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1724375958517,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "Hj2YAP3bzBLQ",
    "outputId": "d65e755c-cde0-4060-f5e5-7def1872e488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://a773d5eddff82d2ec3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a773d5eddff82d2ec3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greet(name, is_morning, temperature):\n",
    "    saluation = \"Good morning\" if is_morning else \"Good evening\"\n",
    "    greeting = f\"{saluation} {name}. It is {temperature} degrees today\"\n",
    "    celsius = (temperature - 32) * 5 / 9\n",
    "    return greeting, round(celsius, 2)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
    "    outputs=[\"text\", \"number\"],\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "executionInfo": {
     "elapsed": 1433,
     "status": "ok",
     "timestamp": 1724376508214,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "vOioPFua0vxG",
    "outputId": "039f162c-b1b4-49bb-b9c6-0b3dd0fbfff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://0c02a1ab4254049bba.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0c02a1ab4254049bba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "from skimage.transform import resize\n",
    "\n",
    "def sepia(input_img):\n",
    "    input_img = resize(input_img, (200, 200))\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189],\n",
    "        [0.349, 0.686, 0.168],\n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(fn=sepia, inputs=gr.Image(), outputs=gr.Image())\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1724377060383,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "pPWyF3zV2zts",
    "outputId": "5359c238-f2a7-4411-cbc5-53a54cc9a77d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hellokevin...\\n your BMI is  ...21.97', '😁', 'Happy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bmi(name, height, weight, feeling):\n",
    "    bmi_val = round(weight / ((height / 100) ** 2),2)\n",
    "    result_emoticon = \"😁\" if bmi_val < 30 else \"😢\"\n",
    "    output_str = 'Hello' + name + \"...\\n your BMI is  ...\" + str(bmi_val)\n",
    "    txt = \"Happy\" if feeling else \"Sad\"\n",
    "    return (output_str, result_emoticon, txt)\n",
    "\n",
    "bmi(\"kevin\", 172, 65, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "executionInfo": {
     "elapsed": 2416,
     "status": "ok",
     "timestamp": 1724377475815,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "tnVboYKP4dq0",
    "outputId": "4748335b-6314-4726-bcee-50aac3cade76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://02c3e588f68946bf38.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://02c3e588f68946bf38.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=bmi,\n",
    "    inputs=[\"text\", gr.Slider(1,200, label=\"Height is cm\"), gr.Slider(1,100, label=\"Weight is kg\"),\n",
    "    gr.Checkbox(label=\"Your Feeling Today\")],\n",
    "    outputs=[\"text\", \"text\", \"text\"],\n",
    "    examples = [['kevin', 170, 65, True],\n",
    "               ['james', 160, 80 ,False]],\n",
    "    live = True,\n",
    "    description = \"Flag if you find an erroneous outptut\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjHWF2qt_TX-"
   },
   "source": [
    "## Blocks\n",
    "- Gradio의 저수준 API로 인터페이스보다 더 많은 사용자 지정 웹 응용 프로그램 및 데모를 만들 수 있습니다(아직 완전히 Python으로).\n",
    "- 인터페이스 클래스에 비해 Blocks는 다음에 대해 더 많은 유연성과 제어 기능을 제공합니다.\n",
    "- Blocks는 또한 탭과 같은 관련 데모를 함께 그룹화하는 방법을 제공합니다.\n",
    "- Blocks 객체를 생성한 다음 컨텍스트로 사용하고(\"with\" 문 사용) Blocks 컨텍스트 내에서 레이아웃, 구성 요소 또는 이벤트를 정의합니다. 마지막으로 launch() 메서드를 호출하여 데모를 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "executionInfo": {
     "elapsed": 1663,
     "status": "ok",
     "timestamp": 1724378923872,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "gqgZWaNO_Vgl",
    "outputId": "6a5ad614-8e90-43f5-ac33-5459287072d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1002: UserWarning: Expected 3 arguments for function <function greet at 0x7db74e073880>, received 1.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1006: UserWarning: Expected at least 3 arguments for function <function greet at 0x7db74e073880>, received 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://66c99d1a9d89629a6c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://66c99d1a9d89629a6c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    text_input = gr.Textbox(label=\"Enter you text\")\n",
    "    output = gr.Textbox(label=\"Output\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "\n",
    "    btn.click(fn=greet, inputs=text_input, outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQoJo5bzAlAF"
   },
   "source": [
    "### 실습\n",
    "코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇\n",
    "\n",
    "- chat_with_tutor 함수: 이 함수는 OpenAI API를 호출하여 학생의 입력에 대한 튜터의 응답을 처리합니다. 이전 대화 내용을 저장하고 이어서 진행합니다.\n",
    "- start_chat 함수: '학습 시작' 버튼을 누르면 튜터의 인사말과 함께 대화가 시작됩니다.\n",
    "- Gradio UI:\n",
    "  - start_button: 학습을 시작하는 버튼입니다. 누르면 튜터의 인사말이 나타납니다.\n",
    "  - tutor_response: 튜터의 대답을 표시하는 텍스트박스입니다.\n",
    "  - user_input: 학생이 질문을 입력할 수 있는 텍스트박스입니다.\n",
    "  - submit_button: 학생이 질문을 제출하는 버튼입니다.\n",
    "  - gr.State(): 대화 기록을 유지하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5294,
     "status": "ok",
     "timestamp": 1724380117632,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "cP5520aXEDBx",
    "outputId": "0d0bd5ae-2736-4a24-ab83-e071a80b54f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m307.2/362.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 3081,
     "status": "ok",
     "timestamp": 1724381036590,
     "user": {
      "displayName": "김홍준",
      "userId": "01118584956690988204"
     },
     "user_tz": -540
    },
    "id": "Y21APbEZATwt",
    "outputId": "79c5db5d-ace4-4e69-b647-11922278fb58"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'좋아요! 변수와 자료형에 대해 설명할게요.\\n\\n변수는 데이터를 저장하는 공간입니다. 자료형은 변수에 저장된 데이터의 종류를 나타냅니다. 주요 자료형은 다음과 같아요:\\n\\n1. **정수(int)**: 1, 2, -3\\n2. **실수(float)**: 3.14, -0.5\\n3. **문자열(str)**: \"안녕하세요\"\\n4. **불(bool)**: True, False\\n\\n연습문제로, 변수 `a`에 정수 10을, 변수 `b`에 문자열 \"파이썬\"을 저장해보세요!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "system_msg=\"\"\"코딩튜터는 고등학생 정보과목에서 알고리즘과 프로그래밍을 학생들이 실습할 수 있게 도와주는 튜터봇입니다.\n",
    "              - 튜터는 \"반가와요~ \"라고 인사말로 학습을 시작합니다.\n",
    "              - 학생이 선택한 섹션으로 학습을 시작하고 먼저 간단하게 섹션 학습내용 요약을 제공합니다.\n",
    "              - 각 섹션별 학습 항목에 대해서 하나씩 개념을 명확하고 친절하게 설명하고 연습문제를 추가로 제공해서 각 개념을 이해하여 활용할 수 있도록 연습 기회를 제공합니다.\n",
    "              - 학생의 답변에 대해서 \"잘했어요!\",\"조금 더 생각해봐요~\" 와 같은 긍정적인 피드백을 제공합니다.\n",
    "              - 대화는 간결하게 유지하며, 최대 100자 이내로 진행합니다.단 코드는 300자 이내로 작성합니다.\n",
    "              - 튜터는 학생들이 자기주도 학습을 할 수 있도록 개인화 된 학습을 제공하고 모든 질의 응답을 한국어로 진행합니다.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # 사용하려는 모델\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요, 파이썬 기초에 대해서 학습을 지도해줘요\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"반갑습니다. 파이썬 기초에 학습해보도록 할게요. 먼저 파이썬의 기본 문법과 개념들을 간단히 요약해드립니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"변수와 자료형에 대해 학습해줘요\"},\n",
    "    ],\n",
    "    temperature=0.5,  # 창의성 조절\n",
    "    max_tokens=300,   # 최대 토큰 수\n",
    "    top_p=1           # Nucleus sampling\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "rOGjk2xMHo7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "Running on public URL: https://e6b7b0c2eefb78bdbd.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e6b7b0c2eefb78bdbd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 채팅함수\n",
    "def chat_with_tutor(user_input, chat_history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
    "\n",
    "    if not chat_history:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"안녕하세요. 파이썬 기초에 대해서 학습을 지도해줘요\"})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",  # 사용하려는 모델\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=300,   # 최대 토큰 수\n",
    "        top_p=1           # Nucleus sampling\n",
    "    )\n",
    "\n",
    "    response_msg = response.choices[0].message.content\n",
    "    chat_history.append({\"role\":\"assistant\", \"content\": response_msg})\n",
    "    return response_msg, chat_history\n",
    "\n",
    "# 그라이도 UI 구성\n",
    "def start_chat():\n",
    "    return \"반가워요, 파이썬 기초를 학습해보도록 할게요. 먼저 파이썬의 기본문법과 개념들을 간단히 요약해드릴게요.\", []\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 파이썬 튜터 봇\")\n",
    "\n",
    "    chat_history = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        start_button = gr.Button(\"학습 시작\")\n",
    "        tutor_response = gr.Textbox(label=\"튜터의 대답\")\n",
    "        user_input = gr.Textbox(label=\"학생의 질문\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"질문 제출\")\n",
    "\n",
    "    start_button.click(start_chat, inputs=[], outputs=[tutor_response, chat_history])\n",
    "    submit_button.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history])\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGAP8w64zw2OGaAvHm4bF8",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
